# -*- coding: utf-8 -*-
"""
Created on Wed Nov 17 15:37:17 2021

@author: s1253
"""
import pickle
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow as tf
from tensorflow.keras.utils import plot_model
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense,Input, Activation, Embedding, LSTM, Concatenate, Reshape, Permute, \
    RepeatVector, Multiply, Dropout, Bidirectional

embed_size = 100
rnn_units = 256

notes, durations= pickle.load(open(r'preprocess/input', 'rb'))
model_input = pickle.load(open(r'preprocess/input', 'rb'))
model_output = pickle.load(open(r'preprocess/output', 'rb'))


note_to_int, int_to_note, duration_to_int, int_to_duration= pickle.load(open(r'preprocess/lookup', 'rb'))

n_notes = len(note_to_int)
n_durations = len(duration_to_int)

notes_input = Input((None,))
durations_input = Input((None,))

x1 = Embedding(len(notes), embed_size)(notes_input)
x2 = Embedding(len(durations), embed_size)(durations_input)

x = Concatenate()([x1, x2])

x = Bidirectional(LSTM(rnn_units, return_sequences=True), merge_mode='sum')(x)
x = Bidirectional(LSTM(rnn_units, return_sequences=True), merge_mode='sum')(x)

x = Dropout(0.2)(x)
num_head = 5
malti_head = []

# malti-head attention

for i in range(num_head):
    e = Dense(1, activation='tanh')(x)
    
    e = Reshape([-1])(e)
    alpha = Activation('softmax')(e)
    
    alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))
    
    c = Multiply()([x, alpha_repeated])
    c = tf.math.reduce_sum(c, axis=1)
    malti_head.append(c)

c = tf.math.reduce_sum(malti_head, axis=0)

notes_out = Dense(n_notes, activation = 'softmax', name = 'pitch')(c)

durations_out = Dense(n_durations, activation = 'softmax', name = 'duration')(c)
   
model = Model([notes_input, durations_input], [notes_out, durations_out])

    
att_model = Model([notes_input, durations_input], alpha)


plot_model(model, to_file=r'model/original_model_structure.png', show_shapes = True, show_layer_names = True)
#model.summary()



optimizer = tf.keras.optimizers.Adam(0.0001)
    

# save model
checkpoint = ModelCheckpoint(r"model/original/weights{epoch:02d}-{loss:.2f}.h5", monitor='loss', verbose=1, save_best_only=True,
mode='min')

model.compile(loss="categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])


# train
'''
model.fit(model_input, model_output
          , epochs=100, batch_size=64
          , validation_split = 0.2
          , callbacks=checkpoint
          , shuffle=True
         )

''' 

#%%

# generate music

import numpy as np
from music21 import instrument, note, stream, chord, duration

model.load_weights(r"model/malti_head/weights92-0.23.h5")
#model.summary()
    
    
    
notes_temp=0.5
duration_temp = 0.5
max_extra_notes = 200
max_seq_len = 32
seq_len = 32

notes = ['START', 'B5', 'A5', 'G5']
durations = [0, 1, 0.5, 0.5]





if seq_len is not None:
    notes = ['START'] * (seq_len - len(notes)) + notes
    durations = [0] * (seq_len - len(durations)) + durations


sequence_length = len(notes)
    
    
prediction_output = []
notes_input_sequence = []
durations_input_sequence = []


# give the model some randomness
def sample_with_temp(preds, temperature):

    if temperature == 0:
        return np.argmax(preds)
    else:
        preds = np.log(preds) / temperature
        exp_preds = np.exp(preds)
        preds = exp_preds / np.sum(exp_preds)
        return np.random.choice(len(preds), p=preds)
    
         
for n, d in zip(notes,durations):
    note_int = note_to_int[n]
    duration_int = duration_to_int[d]
    
    notes_input_sequence.append(note_int)
    durations_input_sequence.append(duration_int)
    
    prediction_output.append([n, d])
    


for note_index in range(max_extra_notes):

    prediction_input = [
        np.array([notes_input_sequence])
        , np.array([durations_input_sequence])
       ]

    notes_prediction, durations_prediction = model.predict(prediction_input, verbose=0)
    
            
    
    i1 = sample_with_temp(notes_prediction[0], notes_temp)
    i2 = sample_with_temp(durations_prediction[0], duration_temp)
    

    note_result = int_to_note[i1]
    duration_result = int_to_duration[i2]
    
    prediction_output.append([note_result, duration_result])

    notes_input_sequence.append(i1)
    durations_input_sequence.append(i2)
    
    if len(notes_input_sequence) > max_seq_len:
        notes_input_sequence = notes_input_sequence[1:]
        durations_input_sequence = durations_input_sequence[1:]
        
        
    if note_result == 'START':
        break

    

midi_stream = stream.Stream()

# create note and chord objects based on the values generated by the model

for pattern in prediction_output:
    note_pattern, duration_pattern = pattern
    # pattern is a chord
    if ('.' in note_pattern):
        notes_in_chord = note_pattern.split('.')
        chord_notes = []
        for current_note in notes_in_chord:
            new_note = note.Note(current_note)
            new_note.duration = duration.Duration(duration_pattern)
            new_note.storedInstrument = instrument.Piano()
            chord_notes.append(new_note)
        new_chord = chord.Chord(chord_notes)
        midi_stream.append(new_chord)
    elif note_pattern == 'rest':
    # pattern is a rest
        new_note = note.Rest()
        new_note.duration = duration.Duration(duration_pattern)
        new_note.storedInstrument = instrument.Piano()
        midi_stream.append(new_note)
    elif note_pattern != 'START':
    # pattern is a note
        new_note = note.Note(note_pattern)
        new_note.duration = duration.Duration(duration_pattern)
        new_note.storedInstrument = instrument.Piano()
        midi_stream.append(new_note)



midi_stream = midi_stream.chordify()
midi_stream.show()
midi_stream.write('midi', fp=r"output/third.mid")


